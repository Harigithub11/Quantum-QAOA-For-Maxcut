{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Data Exploration\n",
    "## Hybrid Quantum-Classical Machine Learning Project\n",
    "\n",
    "This notebook explores the MNIST dataset and verifies our data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.data.dataset import MNISTDataModule, get_mnist_dataloaders\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data module\n",
    "data_module = MNISTDataModule(\n",
    "    data_dir='../data/raw',\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Setup datasets\n",
    "data_module.setup()\n",
    "\n",
    "# Get data loaders\n",
    "train_loader = data_module.train_dataloader()\n",
    "val_loader = data_module.val_dataloader()\n",
    "test_loader = data_module.test_dataloader()\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images\n",
    "images, labels = data_module.get_sample_batch()\n",
    "\n",
    "print(f\"Batch shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"Image value range: [{images.min():.3f}, {images.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first 16 images\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx in range(16):\n",
    "    # Remove normalization for visualization\n",
    "    img = images[idx].squeeze().numpy()\n",
    "    img = img * 0.3081 + 0.1307  # Denormalize\n",
    "    \n",
    "    axes[idx].imshow(img, cmap='gray')\n",
    "    axes[idx].set_title(f'Label: {labels[idx].item()}')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count class distribution in training set\n",
    "train_labels = []\n",
    "for _, labels in train_loader:\n",
    "    train_labels.extend(labels.numpy())\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "unique, counts = np.unique(train_labels, return_counts=True)\n",
    "\n",
    "print(\"Class distribution in training set:\")\n",
    "for digit, count in zip(unique, counts):\n",
    "    print(f\"  Digit {digit}: {count} samples ({count/len(train_labels)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(unique, counts, color='skyblue', edgecolor='navy')\n",
    "plt.xlabel('Digit Class', fontsize=12)\n",
    "plt.ylabel('Number of Samples', fontsize=12)\n",
    "plt.title('MNIST Training Set Class Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xticks(unique)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze pixel value distribution\n",
    "sample_images, _ = data_module.get_sample_batch()\n",
    "pixel_values = sample_images.numpy().flatten()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(pixel_values, bins=50, color='purple', alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Pixel Value (normalized)', fontsize=11)\n",
    "plt.ylabel('Frequency', fontsize=11)\n",
    "plt.title('Distribution of Pixel Values', fontsize=12, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "mean_per_image = sample_images.mean(dim=[1, 2, 3]).numpy()\n",
    "plt.hist(mean_per_image, bins=30, color='green', alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Mean Pixel Value', fontsize=11)\n",
    "plt.ylabel('Frequency', fontsize=11)\n",
    "plt.title('Distribution of Image Means', fontsize=12, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Pixel value statistics:\")\n",
    "print(f\"  Mean: {pixel_values.mean():.4f}\")\n",
    "print(f\"  Std: {pixel_values.std():.4f}\")\n",
    "print(f\"  Min: {pixel_values.min():.4f}\")\n",
    "print(f\"  Max: {pixel_values.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data pipeline with multiple batches\n",
    "print(\"Testing data pipeline...\")\n",
    "\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    if i >= 3:  # Test first 3 batches\n",
    "        break\n",
    "    \n",
    "    print(f\"\\nBatch {i+1}:\")\n",
    "    print(f\"  Images shape: {images.shape}\")\n",
    "    print(f\"  Labels shape: {labels.shape}\")\n",
    "    print(f\"  Device: {images.device}\")\n",
    "    print(f\"  Dtype: {images.dtype}\")\n",
    "    print(f\"  Sample labels: {labels[:10].tolist()}\")\n",
    "\n",
    "print(\"\\n✓ Data pipeline working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepare for Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data format for model\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(\"Data format for model:\")\n",
    "print(f\"  Input shape: {images.shape}  # (batch_size, channels, height, width)\")\n",
    "print(f\"  Expected by ResNet18: [N, 1, 28, 28] ✓\")\n",
    "print(f\"  Labels shape: {labels.shape}  # (batch_size,)\")\n",
    "print(f\"  Number of classes: 10 (digits 0-9)\")\n",
    "\n",
    "# Verify shapes\n",
    "assert images.shape[1:] == (1, 28, 28), \"Image shape incorrect!\"\n",
    "assert labels.shape[0] == images.shape[0], \"Batch size mismatch!\"\n",
    "\n",
    "print(\"\\n✓ Data format verified for model input!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ **Dataset loaded successfully**\n",
    "- Training samples: ~54,000\n",
    "- Validation samples: ~6,000\n",
    "- Test samples: 10,000\n",
    "\n",
    "✅ **Class distribution is balanced** (roughly 10% per class)\n",
    "\n",
    "✅ **Images are properly normalized** (mean ≈ 0, std ≈ 1)\n",
    "\n",
    "✅ **Data pipeline is working** and ready for model training\n",
    "\n",
    "✅ **Input format verified** for ResNet18 + Quantum circuit integration\n",
    "\n",
    "**Next steps:**\n",
    "1. Implement quantum circuit\n",
    "2. Build hybrid model architecture\n",
    "3. Start training!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
